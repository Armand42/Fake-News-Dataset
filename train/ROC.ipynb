{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import readdata\n",
    "from text_vectorizer import CV\n",
    "from text_vectorizer import TFIDF\n",
    "from text_vectorizer import word2vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from text_vectorizer import outlierDection\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Usage:\n",
    "def getRemovedVals(X,Y = None,Ftype = \"\",isTest = False):\n",
    "\n",
    "    X = np.array(X)\n",
    "    index,_ = outlierDection(X,Ftype)\n",
    "    if not isTest:\n",
    "        Y = np.array(Y)\n",
    "        Xrem,Yrem = removeOutliers(index,X,Y,Ftype)\n",
    "        return Xrem,Yrem\n",
    "\n",
    "    else:\n",
    "        Xrem = removeOutliers(index,X,Y,Ftype)\n",
    "        return Xrem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    arg = \"cv\"\n",
    "    dfTrain = readdata.read_clean_data(readdata.TRAINFILEPATH, nolabel=False)\n",
    "    dfTest = readdata.read_clean_data(readdata.TESTFILEPATH, nolabel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_train = dfTrain['text'].to_numpy()\n",
    "    Y_train = dfTrain['label'].to_numpy()\n",
    "    X_test = dfTest['text'].to_numpy()\n",
    "    \n",
    "    X_train = X_train[:5000]\n",
    "    Y_train = Y_train[:5000]\n",
    "    X_test = X_test[:5000]\n",
    "         \n",
    "\n",
    "    if arg == \"cv\":\n",
    "        X_train, X_test, _ = CV(X_train, X_test)  # train shape: (17973, 141221)\n",
    "#         X_train,Y_train = getRemovedVals(X = X_train,Y = Y_train,Ftype = \"CV_Train\",isTest = False)\n",
    "#         X_test = getRemovedVals(X = X_test,Y = None,Ftype = \"CV_Test\",isTest = True)\n",
    "\n",
    "\n",
    "    elif arg == 'tfidf':\n",
    "        X_train, X_test, _ = TFIDF(X_train, X_test)  # shape: (17973, 141221)\n",
    "#         X_train,Y_train = getRemovedVals(X = X_train,Y = Y_train,Ftype = \"TFIDF_Train\",isTest = False)\n",
    "#         X_test = getRemovedVals(X = X_test,Y = None,Ftype = \"TFIDF_Test\",isTest = True)\n",
    "        \n",
    "    elif arg == 'word2vec':\n",
    "        X_train, X_test = word2vec(X_train, X_test)\n",
    "#         X_train,Y_train = getRemovedVals(X = X_train,Y = Y_train,Ftype = \"W2V_Train\",isTest = False)\n",
    "#         X_test = getRemovedVals(X = X_test,Y = None,Ftype = \"W2V_Test\",isTest = True)\n",
    "        \n",
    "    else:\n",
    "        print(\"Error\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # reshape input to be [samples, features]\n",
    "    num_samples = X_train.shape[0]\n",
    "    num_features = X_train.shape[1]\n",
    "    X_train = np.reshape(np.array(X_train), (num_samples, num_features))\n",
    "\n",
    "    # creating space for constant C\n",
    "    c = np.logspace(0, 4, 10)\n",
    "    # various solvers - only used solvers that supported L2\n",
    "    solver = ['newton-cg', 'sag', 'lbfgs', 'liblinear']\n",
    "    param_grid = dict(C=c, solver=solver)\n",
    "    logistic = LogisticRegression(max_iter=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "    grid = GridSearchCV(logistic, param_grid=param_grid, cv=3, verbose=0)\n",
    "    grid_result = grid.fit(X_train, Y_train)\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
