{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'readdata'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b1aa733feb2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mreaddata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtext_vectorizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtext_vectorizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTFIDF\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtext_vectorizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtext_vectorizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moutlierDection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'readdata'"
     ]
    }
   ],
   "source": [
    "import readdata\n",
    "from text_vectorizer import CV\n",
    "from text_vectorizer import TFIDF\n",
    "from text_vectorizer import word2vec\n",
    "from text_vectorizer import outlierDection\n",
    "from OutlierDetectRemove import removeOutliers\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Usage: \n",
    "# 1. python lstm.py cv\n",
    "# 2. python lstm.py tfidf\n",
    "# 3. python lstm.py word2vec\n",
    "\n",
    "# cross-validation 3\n",
    "# number of estimators: 200, 400, 800\n",
    "# max_depth: 1, 5, 9\n",
    "# min_samples_leaf: 2, 4\n",
    "# min_samples_split: 5, 10\n",
    "\n",
    "def getRemovedVals(X,Y = None,Ftype = \"\",isTest = False):\n",
    "\n",
    "    X = np.array(X)\n",
    "    index,_ = outlierDection(X,Ftype)\n",
    "    if not isTest:\n",
    "        Y = np.array(Y)\n",
    "        Xrem,Yrem = removeOutliers(index,X,Y,Ftype)\n",
    "        return Xrem,Yrem\n",
    "\n",
    "    else:\n",
    "        Xrem = removeOutliers(index,X,Y,Ftype)\n",
    "        return Xrem\n",
    "\n",
    "\n",
    "def evaluate(pred, truth):\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(truth, pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(truth, pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(truth, pred)))\n",
    "\n",
    "\n",
    "dfTrain = readdata.read_clean_data(readdata.TRAINFILEPATH,nolabel = False)\n",
    "dfTest = readdata.read_clean_data(readdata.TESTFILEPATH,nolabel = True)\n",
    "\n",
    "X_train = dfTrain['text'].to_numpy()\n",
    "Y_train = dfTrain['label'].to_numpy()\n",
    "X_test = dfTest['text'].to_numpy() # unlabelled\n",
    "\n",
    "\n",
    "# X_train, X_test, _ = CV(X_train, X_test) # train shape: (17973, 141221)\n",
    "# X_train,Y_train = getRemovedVals(X = X_train,Y = Y_train,Ftype = \"CV_Train\",isTest = False)\n",
    "# X_test = getRemovedVals(X = X_test,Y = None,Ftype = \"CV_Test\",isTest = True)\n",
    "\n",
    "\n",
    "# X_train, X_test, _ = TFIDF(X_train, X_test) # shape: (17973, 141221)\n",
    "# X_train,Y_train = getRemovedVals(X = X_train,Y = Y_train,Ftype = \"TFIDF_Train\",isTest = False)\n",
    "# X_test = getRemovedVals(X = X_test,Y = None,Ftype = \"TFIDF_Test\",isTest = True)\n",
    "\n",
    "\n",
    "X_train, X_test = word2vec(X_train, X_test)\n",
    "X_train,Y_train = getRemovedVals(X = X_train,Y = Y_train,Ftype = \"W2V_Train\",isTest = False)\n",
    "X_test = getRemovedVals(X = X_test,Y = None,Ftype = \"W2V_Test\",isTest = True)\n",
    "\n",
    "\n",
    "# below are the hyperparameters to be grid-searched on\n",
    "n_estimators = [200, 400, 800]\n",
    "max_depth = [1, 5, 9]\n",
    "min_samples_leaf = [2, 4]\n",
    "min_samples_split = [5, 10]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                min_samples_split=min_samples_split)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.885997 using {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 800}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e7ac2fd44a73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "roc_auc_score(Y_train, grid_result.predict_proba(X_train)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'readdata'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-688f87a8fa48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mreaddata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'readdata'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
